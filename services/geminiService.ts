import { GoogleGenAI, Chat, GenerateContentResponse, Content } from "@google/genai";
import { Scenario, Choice } from '../types';

if (!process.env.API_KEY) {
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

let chat: Chat | null = null;
let currentUserName: string = 'ì‹ ì…ì‚¬ì›';

export function initializeMentorSession(userName: string): void {
  currentUserName = userName;
  chat = ai.chats.create({
    model: 'gemini-2.5-flash',
    config: {
      systemInstruction: `ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ìµœìƒìœ„ í…Œí¬ ê¸°ì—…ì˜ ì‹œë‹ˆì–´ ë©˜í†  'ì˜¨ë³´ë”© ë‚˜ì¹¨ë°˜'ì…ë‹ˆë‹¤. ì‹ ì…ì‚¬ì› ${currentUserName}ë‹˜ì˜ ì„±ì¥ì„ ë•ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì—­í• ì…ë‹ˆë‹¤. ìƒì‚°ì„±, ì‹œê°„ ê´€ë¦¬, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ë¬¸ì œ í•´ê²°, í˜‘ì—… ë“± ì‹ ì…ì‚¬ì›ì´ ê²ªì„ ìˆ˜ ìˆëŠ” ì–´ë ¤ì›€ì— ëŒ€í•´ ë”°ëœ»í•˜ê³ , ì‹¤ì§ˆì ì´ë©°, ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”. ì´ ì•±ì˜ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë‹¤ë£¨ëŠ” ì›ì¹™ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ë©´ ë”ìš± ì¢‹ìŠµë‹ˆë‹¤. í•­ìƒ ê²©ë ¤í•˜ëŠ” í†¤ì„ ìœ ì§€í•˜ê³ , ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.`,
      // Low latency for chat
      thinkingConfig: { thinkingBudget: 0 },
    },
  });
}

export async function getChatResponseStream(message: string): Promise<AsyncGenerator<GenerateContentResponse>> {
  if (!chat) {
    initializeMentorSession('ì‹ ì…ì‚¬ì›'); // Fallback
  }
  try {
    return chat!.sendMessageStream({ message });
  } catch (error) {
    console.error('Error fetching chat response from Gemini API:', error);
    throw new Error('AI ë©˜í† ë¡œë¶€í„° ë‹µë³€ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }
}

export async function getFeedbackStream(scenario: Scenario, userChoice: Choice): Promise<AsyncGenerator<GenerateContentResponse>> {
  const allChoicesText = scenario.choices.map(c => `- ${c.text}`).join('\n');
  
  const prompt = `
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ìµœìƒìœ„ í…Œí¬ ê¸°ì—…ì˜ ë…¸ë ¨í•œ ì‹œë‹ˆì–´ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤. ì‹ ì… ì£¼ë‹ˆì–´ ì‚¬ì› ${currentUserName}ë‹˜ì—ê²Œ ë©˜í† ë§ì„ ì œê³µí•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•´ ì£¼ì„¸ìš”. ë‹¹ì‹ ì˜ ë§íˆ¬ëŠ” ë”°ëœ»í•˜ê³ , ê±´ì„¤ì ì´ë©°, í†µì°°ë ¥ ìˆëŠ” ì¡°ì–¸ì„ ë‹´ì•„ì•¼ í•©ë‹ˆë‹¤.

    ì‹ ì…ì‚¬ì›ì—ê²Œ ë‹¤ìŒê³¼ ê°™ì€ ì—…ë¬´ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤:
    **ì‹œë‚˜ë¦¬ì˜¤ ì œëª©:** ${scenario.title}
    **ìƒì„¸ ì„¤ëª…:** ${scenario.description}

    ì„ íƒ ê°€ëŠ¥í•œ í–‰ë™ë“¤ì€ ë‹¤ìŒê³¼ ê°™ì•˜ìŠµë‹ˆë‹¤:
    ${allChoicesText}

    **ì‹ ì…ì‚¬ì›ì˜ ì„ íƒ:** "${userChoice.text}"

    ì´ ì„ íƒì— ëŒ€í•´ ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°±ì„ ì œê³µí•´ ì£¼ì„¸ìš”. **í”¼ë“œë°±ì€ ë°˜ë“œì‹œ ì•„ë˜ì˜ ë§ˆí¬ë‹¤ìš´ ì„œì‹ì„ ì •í™•íˆ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ê° ì„¹ì…˜ ì œëª© ì•ì—ëŠ” ì§€ì •ëœ ì´ëª¨ì§€ë¥¼ í¬í•¨í•˜ê³ , ì„¹ì…˜ ì‚¬ì´ëŠ” ë°˜ë“œì‹œ '---' ìˆ˜í‰ì„ ìœ¼ë¡œ êµ¬ë¶„í•´ì•¼ í•©ë‹ˆë‹¤. ë¬¸ë‹¨ ì‚¬ì´ì—ëŠ” ë¹ˆ ì¤„ì„ ë„£ì–´ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.**

    ### ğŸ¤· ë‹¹ì‹ ì˜ ì„ íƒì— ëŒ€í•œ ë¶„ì„
    (ì—¬ê¸°ì— ë‚´ìš© ì‘ì„±: ${currentUserName}ë‹˜ì˜ ì„ íƒì„ ë¨¼ì € ì¸ì •í•˜ê³ , í•´ë‹¹ ì„ íƒì´ ì‹¤ì œ ì—…ë¬´ í™˜ê²½ì—ì„œ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì¥ì ê³¼ ë‹¨ì ì„ ê· í˜• ìˆê²Œ ë¶„ì„. ë¬¸ë‹¨ êµ¬ë¶„ì„ ìœ„í•´ ë¹ˆ ì¤„ ì‚¬ìš©.)

    ---

    ### ğŸ’¡ ì¶”ì²œí•˜ëŠ” ì ‘ê·¼ ë°©ì‹
    (ì—¬ê¸°ì— ë‚´ìš© ì‘ì„±: ì´ ì‹œë‚˜ë¦¬ì˜¤ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ê°€ì¥ íš¨ê³¼ì ì¸ ì—…ë¬´ ì›ì¹™ì´ë‚˜ ì‚¬ê³  ëª¨ë¸ ì„¤ëª…. ê°€ì¥ ì´ìƒì ì¸ í–‰ë™ê³¼ ê·¸ ì´ìœ ë¥¼ ëª…í™•íˆ ì œì‹œ. ë¬¸ë‹¨ êµ¬ë¶„ì„ ìœ„í•´ ë¹ˆ ì¤„ ì‚¬ìš©.)

    ---

    ### ğŸ¤” ë‹¤ë¥¸ ì„ íƒì§€ë“¤ì— ëŒ€í•œ ê³ ì°°
    (ì—¬ê¸°ì— ë‚´ìš© ì‘ì„±: ì„ íƒë˜ì§€ ì•Šì€ ë‹¤ë¥¸ ì˜µì…˜ë“¤ì´ ì™œ ëœ íš¨ê³¼ì ì¸ì§€ ê°„ëµí•˜ê²Œ ì„¤ëª…. ê° ì„ íƒì§€ì— ëŒ€í•´ ë³„ë„ì˜ ë¬¸ë‹¨ìœ¼ë¡œ ì„¤ëª….)

    ---

    ### â­ í•µì‹¬ ì •ë¦¬
    > (ì—¬ê¸°ì— ë‚´ìš© ì‘ì„±: ${currentUserName}ë‹˜ì´ ì•ìœ¼ë¡œ ìœ ì‚¬í•œ ìƒí™©ì—ì„œ ê¸°ì–µí•˜ê³  ì ìš©í•  ìˆ˜ ìˆëŠ”, í˜ì„ ì‹¤ì–´ì£¼ëŠ” í•µì‹¬ ì›ì¹™ì´ë‚˜ êµí›ˆì„ blockquote í˜•ì‹ìœ¼ë¡œ ì‘ì„±.)

    **í”¼ë“œë°± ì‘ì„±ì´ ëë‚˜ë©´, ë°˜ë“œì‹œ ë‹¤ìŒ ì¤„ì— %%%QUESTIONS%%% ë¼ëŠ” êµ¬ë¶„ìë¥¼ ì‚½ì…í•´ì£¼ì„¸ìš”.**

    ê·¸ ë‹¤ìŒ ì¤„ë¶€í„°, ì´ ì£¼ì œì— ëŒ€í•´ ë” ê¹Šì´ ìƒê°í•´ë³¼ ìˆ˜ ìˆëŠ” 3ê°œì˜ ì—°ê´€ ì§ˆë¬¸ì„ ê°ê° í•œ ì¤„ì”© ì‘ì„±í•´ì£¼ì„¸ìš”. ì§ˆë¬¸ ì•ì—ëŠ” ë²ˆí˜¸ë‚˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ë¶™ì´ì§€ ë§ˆì„¸ìš”.
  `;

  try {
    const stream = await ai.models.generateContentStream({
      model: 'gemini-2.5-flash',
      contents: prompt,
      config: {
        // Disable thinking for faster initial response
        thinkingConfig: { thinkingBudget: 0 },
      },
    });
    return stream;
  } catch (error) {
    console.error('Error fetching feedback from Gemini API:', error);
    throw new Error('AIë¡œë¶€í„° í”¼ë“œë°±ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }
}

export async function getFollowUpAnswerStream(
  scenario: Scenario,
  originalFeedback: string,
  question: string
): Promise<AsyncGenerator<GenerateContentResponse>> {
  const prompt = `
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ìµœìƒìœ„ í…Œí¬ ê¸°ì—…ì˜ ì‹œë‹ˆì–´ ë©˜í†  'ì˜¨ë³´ë”© ë‚˜ì¹¨ë°˜'ì…ë‹ˆë‹¤. ì‹ ì…ì‚¬ì›ì˜ ì„±ì¥ì„ ë•ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì—­í• ì…ë‹ˆë‹¤.

    **ìƒí™©:**
    - **ì‹œë‚˜ë¦¬ì˜¤:** ${scenario.title} (${scenario.description})
    - **ë‹¹ì‹ ì˜ ì´ì „ ì¡°ì–¸:**
    ---
    ${originalFeedback}
    ---

    ìœ„ ìƒí™©ê³¼ ì¡°ì–¸ì— ì´ì–´, ì‹ ì…ì‚¬ì› ${currentUserName}ë‹˜ì´ ë‹¤ìŒê³¼ ê°™ì€ ì¶”ê°€ ì§ˆë¬¸ì„ í–ˆìŠµë‹ˆë‹¤.
    **ì‹ ì…ì‚¬ì›ì˜ ì§ˆë¬¸:** "${question}"

    ì´ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³ , ì‹¤ì§ˆì ì´ë©°, ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”. ë‹µë³€ì€ ì´ì „ ì¡°ì–¸ì˜ ë§¥ë½ì„ ìœ ì§€í•˜ë©°, ì‹ ì…ì‚¬ì›ì´ í•œ ë‹¨ê³„ ë” ì„±ì¥í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.
  `;
  try {
    const stream = await ai.models.generateContentStream({
      model: 'gemini-2.5-flash',
      contents: prompt,
      config: {
        // Disable thinking for faster initial response
        thinkingConfig: { thinkingBudget: 0 },
      },
    });
    return stream;
  } catch (error) {
    console.error('Error fetching follow-up answer from Gemini API:', error);
    throw new Error('AI ë©˜í† ë¡œë¶€í„° ì¶”ê°€ ë‹µë³€ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }
}